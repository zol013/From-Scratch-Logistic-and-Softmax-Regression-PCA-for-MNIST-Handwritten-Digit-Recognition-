{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_Z3ehM4CpPvr"},"outputs":[],"source":["#data.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abRl33eIpPvs"},"outputs":[],"source":["import idx2numpy\n","import numpy as np\n","import os\n","import pickle\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3AGtpkKJpPvt"},"outputs":[],"source":["def load_data(data_directory, train = True):\n","    if train:\n","        images = idx2numpy.convert_from_file(os.path.join(data_directory, 'train-images.idx3-ubyte'))\n","        labels = idx2numpy.convert_from_file(os.path.join(data_directory, 'train-labels.idx1-ubyte'))\n","    else:\n","        images = idx2numpy.convert_from_file(os.path.join(data_directory, 't10k-images.idx3-ubyte'))\n","        labels = idx2numpy.convert_from_file(os.path.join(data_directory, 't10k-labels.idx1-ubyte'))\n","\n","    vdim = images.shape[1] * images.shape[2]\n","    vectors = np.empty([images.shape[0], vdim])\n","    for imnum in range(images.shape[0]):\n","        imvec = images[imnum, :, :].reshape(vdim, 1).squeeze()\n","        vectors[imnum, :] = imvec\n","\n","    return vectors, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lhk3vau6pPvt"},"outputs":[],"source":["train_images, train_labels = load_data('data')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZtThVf0pPvt"},"outputs":[],"source":["test_images, test_labels = load_data('data', train = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OhHVHR4EpPvt"},"outputs":[],"source":["def z_score_normalize(X, u = None, sd = None):\n","    \"\"\"\n","    Performs z-score normalization on X.\n","\n","    f(x) = (x - μ) / σ\n","        where\n","            μ = mean of x\n","            σ = standard deviation of x\n","\n","    Parameters\n","    ----------\n","    X : np.array\n","        The data to z-score normalize\n","    u (optional) : np.array\n","        The mean to use when normalizing\n","    sd (optional) : np.array\n","        The standard deviation to use when normalizing\n","\n","    Returns\n","    -------\n","        Tuple:\n","            Transformed dataset with mean 0 and stdev 1\n","            Computed statistics (mean and stdev) for the dataset to undo z-scoring.\n","    \"\"\"\n","\n","    u = np.mean(X, axis = 1)\n","    sd = np.std(X, axis = 1)\n","    X_normalized = np.copy(X)\n","    for i in range(len(X)):\n","        X_normalized[i] = (X[i] - u[i])/sd[i]\n","\n","\n","    return X_normalized, u, sd\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1wWfgCRpPvu"},"outputs":[],"source":["train_normalized, u, sd = z_score_normalize(train_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZU2AodhHpPvu","outputId":"2f15aa13-df51-4058-dec0-0ca0db581f50"},"outputs":[{"data":{"text/plain":["9"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["np.max(train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xnLSuko-pPvv"},"outputs":[],"source":["def min_max_normalize(X, _min = None, _max = None):\n","    \"\"\"\n","    Performs min-max normalization on X.\n","\n","    f(x) = (x - min(x)) / (max(x) - min(x))\n","\n","    Parameters\n","    ----------\n","    X : np.array\n","        The data to min-max normalize\n","    _min (optional) : np.array\n","        The min to use when normalizing\n","    _max (optional) : np.array\n","        The max to use when normalizing\n","\n","    Returns\n","    -------\n","        Tuple:\n","            Transformed dataset with all values in [0,1]\n","            Computed statistics (min and max) for the dataset to undo min-max normalization.\n","    \"\"\"\n","    X_min = np.zeros(len(X))\n","    X_max = np.zeros(len(X))\n","    X_normalized = np.zeros((len(X), len(X[0])))\n","\n","    for i in range(len(X)):\n","        X_min[i] = np.min(X[i])\n","        X_max[i] = np.max(X[i])\n","        X_normalized[i] = (X[i] - X_min[i]) / (X_max[i] - X_min[i])\n","\n","    return X_normalized, X_min, X_max\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-EPrS4CcpPvv"},"outputs":[],"source":["a = np.eye(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AxLi3jVgpPvv","outputId":"6c3266db-6f83-48b7-b6dc-ae338ce6f3c6"},"outputs":[{"data":{"text/plain":["array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["a[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2KKicVKqpPvv"},"outputs":[],"source":["b = np.zeros((3, 7))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08Hi8_BXpPvv"},"outputs":[],"source":["def onehot_encode(y):\n","    \"\"\"\n","    Performs one-hot encoding on y.\n","\n","    Ideas:\n","        NumPy's `eye` function\n","\n","    Parameters\n","    ----------\n","    y : np.array\n","        1d array (length n) of targets (k)\n","\n","    Returns\n","    -------\n","        2d array (shape n*k) with each row corresponding to a one-hot encoded version of the original value.\n","    \"\"\"\n","    diagonals = np.eye(10)\n","    y_encoded = np.zeros((len(y), 10))\n","\n","    for i in range(len(y)):\n","        y_encoded[i] = diagonals[y[i]]\n","\n","    return y_encoded\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjDixD-wpPvv"},"outputs":[],"source":["labels_encoded = onehot_encode(train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35FEg9JLpPvw","outputId":"1a764887-085b-4380-ea97-61c735b4c188"},"outputs":[{"data":{"text/plain":["array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["labels_encoded[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YD427nsypPvw","outputId":"840d2ac0-4f6e-48aa-dec9-60fe1e23f47c"},"outputs":[{"data":{"text/plain":["array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["labels_encoded[-9:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ik9t3gJWpPvw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3rVxYKApPvw"},"outputs":[],"source":["def onehot_decode(y):\n","    \"\"\"\n","    Performs one-hot decoding on y.\n","\n","    Ideas:\n","        NumPy's `argmax` function\n","\n","    Parameters\n","    ----------\n","    y : np.array\n","        2d array (shape n*k) with each row corresponding to a one-hot encoded version of the original value.\n","\n","    Returns\n","    -------\n","        1d array (length n) of targets (k)\n","    \"\"\"\n","    y_decoded = np.argmax(y, axis = 1)\n","\n","    return y_decoded\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4bdk2Y6MpPvw"},"outputs":[],"source":["labels_decoded = onehot_decode(labels_encoded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iClIh7bmpPvw"},"outputs":[],"source":["a = np.array([1,3,5,7,9,11,13,15])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DUD9aYuypPvw"},"outputs":[],"source":["b = np.random.permutation(8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yobnw0fzpPvw"},"outputs":[],"source":["c = a[b]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5l2LIUZupPvw","outputId":"8f48c3cc-f7a8-411e-8757-bab10b153334"},"outputs":[{"data":{"text/plain":["array([15,  7, 11,  1, 13,  3,  9,  5])"]},"execution_count":159,"metadata":{},"output_type":"execute_result"}],"source":["c"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMQrLgU_pPvw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KClJW1MQpPvw","outputId":"575782dc-07dd-4c8d-e3c4-44362d088df2"},"outputs":[{"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-2-6aa2c81c05bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9cb2W8F4pPvw"},"outputs":[],"source":["def shuffle(dataset):\n","    \"\"\"\n","    Shuffle dataset.\n","\n","    Make sure that corresponding images and labels are kept together.\n","    Ideas:\n","        NumPy array indexing\n","            https://numpy.org/doc/stable/user/basics.indexing.html#advanced-indexing\n","\n","    Parameters\n","    ----------\n","    dataset\n","        Tuple containing\n","            Images (X)\n","            Labels (y)\n","\n","    Returns\n","    -------\n","        Tuple containing\n","            Images (X)\n","            Labels (y)\n","    \"\"\"\n","    X, y = dataset\n","    indices = np.random.permutation(len(X))\n","    X_shuffled = X[indices]\n","    y_shuffled = y[indices]\n","\n","    return X_shuffled, y_shuffled\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R46HsfqopPvw"},"outputs":[],"source":["image_shuffled, label_shuffled = shuffle((train_images, train_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0mv9hJppPvw","outputId":"faef6508-660f-4a6f-bf45-f86e2db0e977"},"outputs":[{"data":{"text/plain":["array([6, 5, 1, ..., 1, 1, 4], dtype=uint8)"]},"execution_count":162,"metadata":{},"output_type":"execute_result"}],"source":["label_shuffled"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M1oorbnOpPvw"},"outputs":[],"source":["a = np.array([[3,4], [5,6], [7,8]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9mVTfry2pPvw"},"outputs":[],"source":["b = np.insert(a, 0, 1, axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VE0Anc90pPvw","outputId":"7e8c990c-feef-41d5-b08f-3d180bccc3b3"},"outputs":[{"data":{"text/plain":["array([[1, 3, 4],\n","       [1, 5, 6],\n","       [1, 7, 8]])"]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDd2XoWspPvw"},"outputs":[],"source":["def append_bias(X):\n","    \"\"\"\n","    Append bias term for dataset.\n","\n","    Parameters\n","    ----------\n","    X\n","        2d numpy array with shape (N,d)\n","\n","    Returns\n","    -------\n","        2d numpy array with shape ((N+1),d)\n","    \"\"\"\n","    X_new = np.insert(X, 0, 1, axis = 1)\n","    return X_new\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IRLai-9bpPvw"},"outputs":[],"source":["train_new = append_bias(train_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fc6krtVpPvw","outputId":"132a73a5-463d-409a-87de-6151c2d5ff2e"},"outputs":[{"data":{"text/plain":["(60000, 785)"]},"execution_count":175,"metadata":{},"output_type":"execute_result"}],"source":["train_new.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoKvsrdZpPvx"},"outputs":[],"source":["def generate_minibatches(dataset, batch_size=64):\n","    X, y = dataset\n","    l_idx, r_idx = 0, batch_size\n","    while r_idx < len(X):\n","        yield X[l_idx:r_idx], y[l_idx:r_idx]\n","        l_idx, r_idx = r_idx, r_idx + batch_size\n","\n","    yield X[l_idx:], y[l_idx:]\n","\n","def generate_k_fold_set(dataset, k = 5):\n","    X, y = dataset\n","    if k == 1:\n","        yield (X, y), (X[len(X):], y[len(y):])\n","        return\n","\n","    order = np.random.permutation(len(X))\n","\n","    fold_width = len(X) // k\n","\n","    l_idx, r_idx = 0, fold_width\n","\n","    for i in range(k):\n","        train = np.concatenate([X[order[:l_idx]], X[order[r_idx:]]]), np.concatenate([y[order[:l_idx]], y[order[r_idx:]]])\n","        validation = X[order[l_idx:r_idx]], y[order[l_idx:r_idx]]\n","        yield train, validation\n","        l_idx, r_idx = r_idx, r_idx + fold_width\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bpx8jXWfpPvx"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QGwpsCGypPvx"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5MgqHHipPvx"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4JOZO4OcpPvx"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2J13qoCWpPvx"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}